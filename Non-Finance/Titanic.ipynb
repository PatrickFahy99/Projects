{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"/Users/patrickfahy99/Documents/Kaggle_datasets/titanic/train.csv\")\n",
    "X_test = pd.read_csv(\"/Users/patrickfahy99/Documents/Kaggle_datasets/titanic/test.csv\")\n",
    "\n",
    "train.index = train[\"PassengerId\"]\n",
    "del train[\"PassengerId\"]\n",
    "del train[\"Cabin\"]\n",
    "del train['Ticket']\n",
    "\n",
    "X_test.index = X_test[\"PassengerId\"]\n",
    "del X_test[\"PassengerId\"]\n",
    "del X_test[\"Cabin\"]\n",
    "del X_test[\"Ticket\"]\n",
    "\n",
    "y_train = train[\"Survived\"]\n",
    "X_train = train.drop(labels = [\"Survived\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cabin column simply has too many missing values to be of great use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    891 non-null    int64  \n",
      " 1   Name      891 non-null    object \n",
      " 2   Sex       891 non-null    object \n",
      " 3   Age       714 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 62.6+ KB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 892 to 1309\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Name      418 non-null    object \n",
      " 2   Sex       418 non-null    object \n",
      " 3   Age       332 non-null    float64\n",
      " 4   SibSp     418 non-null    int64  \n",
      " 5   Parch     418 non-null    int64  \n",
      " 6   Fare      417 non-null    float64\n",
      " 7   Embarked  418 non-null    object \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 29.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Having a look at the datasets to look for missing values\n",
    "\n",
    "X_train.info()\n",
    "print(\"\\n\")\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the train columns with missing data are Age and Embarked.\n",
    "The test columns with missing data are Age and fare.\n",
    "\n",
    "I will input missing Age and Fare values with the median, and the Embarked with the mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X_train, X_test]\n",
    "\n",
    "for i in data:    \n",
    "    #complete missing age with median\n",
    "    i['Age'].fillna(i['Age'].median(), inplace = True)\n",
    "\n",
    "    #complete embarked with mode\n",
    "    i['Embarked'].fillna(i['Embarked'].mode()[0], inplace = True)\n",
    "\n",
    "    #complete missing fare with median\n",
    "    i['Fare'].fillna(i['Fare'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in data:    \n",
    "    #Discrete variables\n",
    "    i['FamilySize'] = i['SibSp'] + i['Parch'] + 1\n",
    "\n",
    "    i['IsAlone'] = 1 #initialize to yes/1 is alone\n",
    "    i['IsAlone'].loc[i['FamilySize'] > 1] = 0 # now update to no/0 if family size is greater than 1\n",
    "\n",
    "    #quick and dirty code split title from name: http://www.pythonforbeginners.com/dictionary/python-split\n",
    "    i['Title'] = i['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "\n",
    "\n",
    "    #Continuous variable bins; qcut vs cut: https://stackoverflow.com/questions/30211923/what-is-the-difference-between-pandas-qcut-and-pandas-cut\n",
    "    #Fare Bins/Buckets using qcut or frequency bins: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "    i['FareBin'] = pd.qcut(i['Fare'], 4)\n",
    "    \n",
    "    del i['Name']\n",
    "    del i['SibSp']\n",
    "    del i['Parch']\n",
    "    del i['Fare']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Mlle              2\n",
       "Major             2\n",
       "Col               2\n",
       "Mme               1\n",
       "Jonkheer          1\n",
       "Don               1\n",
       "Capt              1\n",
       "Lady              1\n",
       "Sir               1\n",
       "the Countess      1\n",
       "Ms                1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are multiple entries which only come up a few times, we will group these together as 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        240\n",
       "Miss       78\n",
       "Mrs        72\n",
       "Master     21\n",
       "Misc        7\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_train = (X_train['Title'].value_counts() < 8)\n",
    "X_train['Title'] = X_train['Title'].apply(lambda x: 'Misc' if other_train.loc[x] == True else x)\n",
    "\n",
    "other_test = (X_test['Title'].value_counts() < 8)\n",
    "X_test['Title'] = X_test['Title'].apply(lambda x: 'Misc' if other_test.loc[x] == True else x)\n",
    "\n",
    "X_test['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Sex_Code</th>\n",
       "      <th>Embarked_Code</th>\n",
       "      <th>Title_Code</th>\n",
       "      <th>FareBin_Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass   Age  FamilySize  IsAlone  Sex_Code  Embarked_Code  \\\n",
       "PassengerId                                                               \n",
       "1                 3  22.0           2        0         1              2   \n",
       "2                 1  38.0           2        0         0              0   \n",
       "3                 3  26.0           1        1         0              2   \n",
       "4                 1  35.0           2        0         0              2   \n",
       "5                 3  35.0           1        1         1              2   \n",
       "...             ...   ...         ...      ...       ...            ...   \n",
       "887               2  27.0           1        1         1              2   \n",
       "888               1  19.0           1        1         0              2   \n",
       "889               3  28.0           4        0         0              2   \n",
       "890               1  26.0           1        1         1              0   \n",
       "891               3  32.0           1        1         1              1   \n",
       "\n",
       "             Title_Code  FareBin_Code  \n",
       "PassengerId                            \n",
       "1                     3             0  \n",
       "2                     4             3  \n",
       "3                     2             1  \n",
       "4                     4             3  \n",
       "5                     3             1  \n",
       "...                 ...           ...  \n",
       "887                   1             1  \n",
       "888                   2             2  \n",
       "889                   2             2  \n",
       "890                   3             2  \n",
       "891                   3             0  \n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "label = LabelEncoder()\n",
    "for i in data:    \n",
    "    i['Sex_Code'] = label.fit_transform(i['Sex'])\n",
    "    i['Embarked_Code'] = label.fit_transform(i['Embarked'])\n",
    "    i['Title_Code'] = label.fit_transform(i['Title'])\n",
    "    i['FareBin_Code'] = label.fit_transform(i['FareBin'])\n",
    "    del i['Sex']\n",
    "    del i['Embarked']\n",
    "    del i['Title']\n",
    "    del i['FareBin']\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/891 with 0 missing, elapsed time: 0.118\n",
      "Imputing row 101/891 with 0 missing, elapsed time: 0.118\n",
      "Imputing row 201/891 with 0 missing, elapsed time: 0.119\n",
      "Imputing row 301/891 with 0 missing, elapsed time: 0.119\n",
      "Imputing row 401/891 with 0 missing, elapsed time: 0.119\n",
      "Imputing row 501/891 with 0 missing, elapsed time: 0.121\n",
      "Imputing row 601/891 with 0 missing, elapsed time: 0.121\n",
      "Imputing row 701/891 with 0 missing, elapsed time: 0.121\n",
      "Imputing row 801/891 with 0 missing, elapsed time: 0.122\n",
      "Imputing row 1/418 with 0 missing, elapsed time: 0.035\n",
      "Imputing row 101/418 with 0 missing, elapsed time: 0.035\n",
      "Imputing row 201/418 with 0 missing, elapsed time: 0.036\n",
      "Imputing row 301/418 with 0 missing, elapsed time: 0.036\n",
      "Imputing row 401/418 with 0 missing, elapsed time: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/fancyimpute/solver.py:55: UserWarning: Input matrix is not missing any values\n",
      "  warnings.warn(\"Input matrix is not missing any values\")\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/fancyimpute/solver.py:55: UserWarning: Input matrix is not missing any values\n",
      "  warnings.warn(\"Input matrix is not missing any values\")\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import KNN\n",
    "X_train_imp = KNN(k=5).fit_transform(X_train)\n",
    "X_test_imp = KNN(k=5).fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age'] = X_train_imp[:,1]\n",
    "X_test['Age'] = X_test_imp[:,1]\n",
    "\n",
    "for i in data:\n",
    "    i['AgeBin'] = pd.cut(i['Age'].astype(int), 5)\n",
    "    del i['Age']\n",
    "    i['AgeBin_Code'] = label.fit_transform(i['AgeBin'])\n",
    "    del i['AgeBin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = model_selection.train_test_split(X_train, y_train, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "\n",
    "#Machine Learning Algorithm (MLA) Selection and Initialization\n",
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "    ]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "scaler.fit(X_train1)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "X_train1 = scaler.transform(X_train1)\n",
    "X_val1 = scaler.transform(X_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate mean absolute error\n",
    "def mae(y_val1, y_pred):\n",
    "    return np.mean(abs(y_val1 - y_pred))\n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model):\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train1, y_train1)\n",
    "    \n",
    "    # Make predictions and evalute\n",
    "    model_pred = model.predict(X_val1)\n",
    "    model_mae = mae(y_val1, model_pred)\n",
    "    \n",
    "    # Return the performance metric\n",
    "    return model_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16591928251121077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = ensemble.AdaBoostClassifier()\n",
    "ada_mae = fit_and_evaluate(ada)\n",
    "ada_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set: MAE = 0.1659\n",
      "Performance on the test set: MAE = 0.1614\n",
      "Performance on the test set: MAE = 0.1659\n",
      "Performance on the test set: MAE = 0.1704\n",
      "Performance on the test set: MAE = 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set: MAE = 0.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the test set: MAE = 0.2018\n",
      "Performance on the test set: MAE = 0.3498\n",
      "Performance on the test set: MAE = 0.2152\n",
      "Performance on the test set: MAE = 0.2063\n",
      "Performance on the test set: MAE = 0.1973\n",
      "Performance on the test set: MAE = 0.2287\n",
      "Performance on the test set: MAE = 0.2287\n",
      "Performance on the test set: MAE = 0.1883\n",
      "Performance on the test set: MAE = 0.2197\n",
      "Performance on the test set: MAE = 0.2197\n",
      "Performance on the test set: MAE = 0.2108\n",
      "Performance on the test set: MAE = 0.1749\n",
      "Performance on the test set: MAE = 0.1839\n",
      "Performance on the test set: MAE = 0.2152\n",
      "Performance on the test set: MAE = 0.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/patrickfahy99/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for model in MLA:\n",
    "    print('Performance on the test set: MAE = %0.4f' % fit_and_evaluate(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.AdaBoostClassifier()\n",
    "\n",
    "# Number of trees used in the boosting process\n",
    "n_estimators = [10, 25, 50, 75, 100, 150, 250]\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.5, 1]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'learning_rate': learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=model,\n",
    "                               param_distributions=hyperparameter_grid,\n",
    "                               cv=4, n_iter=25, \n",
    "                               scoring = 'neg_mean_absolute_error',\n",
    "                               n_jobs = -1, verbose = 1, \n",
    "                               return_train_score = True,\n",
    "                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise-deprecating',\n",
       "                   estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                base_estimator=None,\n",
       "                                                learning_rate=1.0,\n",
       "                                                n_estimators=50,\n",
       "                                                random_state=None),\n",
       "                   iid='warn', n_iter=25, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1, 0.5,\n",
       "                                                          1],\n",
       "                                        'n_estimators': [10, 25, 50, 75, 100,\n",
       "                                                         150, 250]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on the training data\n",
    "random_cv.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.147767</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.016078</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 75, 'learning_rate': 0.1}</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.184524</td>\n",
       "      <td>-0.174699</td>\n",
       "      <td>-0.138554</td>\n",
       "      <td>-0.166168</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.157371</td>\n",
       "      <td>-0.173307</td>\n",
       "      <td>-0.163169</td>\n",
       "      <td>0.006399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.312475</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>150</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 150, 'learning_rate': 0.05}</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.184524</td>\n",
       "      <td>-0.174699</td>\n",
       "      <td>-0.144578</td>\n",
       "      <td>-0.167665</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.164</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.157371</td>\n",
       "      <td>-0.173307</td>\n",
       "      <td>-0.163169</td>\n",
       "      <td>0.006399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.557303</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>0.063839</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>250</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 250, 'learning_rate': 0.05}</td>\n",
       "      <td>-0.172619</td>\n",
       "      <td>-0.184524</td>\n",
       "      <td>-0.180723</td>\n",
       "      <td>-0.144578</td>\n",
       "      <td>-0.170659</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.163347</td>\n",
       "      <td>-0.175299</td>\n",
       "      <td>-0.164661</td>\n",
       "      <td>0.006449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.294656</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.033567</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>150</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 150, 'learning_rate': 0.1}</td>\n",
       "      <td>-0.172619</td>\n",
       "      <td>-0.184524</td>\n",
       "      <td>-0.180723</td>\n",
       "      <td>-0.150602</td>\n",
       "      <td>-0.172156</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.163347</td>\n",
       "      <td>-0.173307</td>\n",
       "      <td>-0.164163</td>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025706</td>\n",
       "      <td>0.004791</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 10, 'learning_rate': 0.5}</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>-0.196429</td>\n",
       "      <td>-0.198795</td>\n",
       "      <td>-0.138554</td>\n",
       "      <td>-0.178144</td>\n",
       "      <td>0.024075</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.167331</td>\n",
       "      <td>-0.185259</td>\n",
       "      <td>-0.172147</td>\n",
       "      <td>0.007575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.147719</td>\n",
       "      <td>0.015746</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>50</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.1}</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.150602</td>\n",
       "      <td>-0.179641</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.167331</td>\n",
       "      <td>-0.185259</td>\n",
       "      <td>-0.174647</td>\n",
       "      <td>0.008209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.190281</td>\n",
       "      <td>0.011216</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>100</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 100, 'learning_rate': 0.05}</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.156627</td>\n",
       "      <td>-0.181138</td>\n",
       "      <td>0.014177</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.167331</td>\n",
       "      <td>-0.185259</td>\n",
       "      <td>-0.175147</td>\n",
       "      <td>0.008573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 0.5}</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.180723</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.184132</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>-0.163347</td>\n",
       "      <td>-0.181275</td>\n",
       "      <td>-0.168655</td>\n",
       "      <td>0.007618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179080</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.025321</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'n_estimators': 75, 'learning_rate': 0.5}</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>-0.196429</td>\n",
       "      <td>-0.192771</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.188623</td>\n",
       "      <td>0.006774</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-0.163347</td>\n",
       "      <td>-0.181275</td>\n",
       "      <td>-0.169655</td>\n",
       "      <td>0.006909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.102453</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 50, 'learning_rate': 1}</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>-0.198795</td>\n",
       "      <td>-0.186747</td>\n",
       "      <td>-0.188623</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.177291</td>\n",
       "      <td>-0.203187</td>\n",
       "      <td>-0.179120</td>\n",
       "      <td>0.014404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "14       0.147767      0.004879         0.016078        0.001641   \n",
       "7        0.312475      0.010468         0.056200        0.001291   \n",
       "1        0.557303      0.007465         0.063839        0.002208   \n",
       "6        0.294656      0.003662         0.033567        0.001601   \n",
       "3        0.025706      0.004791         0.003514        0.000755   \n",
       "9        0.147719      0.015746         0.013750        0.002883   \n",
       "17       0.190281      0.011216         0.024975        0.004491   \n",
       "23       0.098255      0.003906         0.012836        0.001594   \n",
       "2        0.179080      0.013133         0.025321        0.005563   \n",
       "22       0.102453      0.004819         0.014511        0.002820   \n",
       "\n",
       "   param_n_estimators param_learning_rate  \\\n",
       "14                 75                 0.1   \n",
       "7                 150                0.05   \n",
       "1                 250                0.05   \n",
       "6                 150                 0.1   \n",
       "3                  10                 0.5   \n",
       "9                  50                 0.1   \n",
       "17                100                0.05   \n",
       "23                 50                 0.5   \n",
       "2                  75                 0.5   \n",
       "22                 50                   1   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "14    {'n_estimators': 75, 'learning_rate': 0.1}          -0.166667   \n",
       "7   {'n_estimators': 150, 'learning_rate': 0.05}          -0.166667   \n",
       "1   {'n_estimators': 250, 'learning_rate': 0.05}          -0.172619   \n",
       "6    {'n_estimators': 150, 'learning_rate': 0.1}          -0.172619   \n",
       "3     {'n_estimators': 10, 'learning_rate': 0.5}          -0.178571   \n",
       "9     {'n_estimators': 50, 'learning_rate': 0.1}          -0.190476   \n",
       "17  {'n_estimators': 100, 'learning_rate': 0.05}          -0.190476   \n",
       "23    {'n_estimators': 50, 'learning_rate': 0.5}          -0.178571   \n",
       "2     {'n_estimators': 75, 'learning_rate': 0.5}          -0.178571   \n",
       "22      {'n_estimators': 50, 'learning_rate': 1}          -0.178571   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "14          -0.184524          -0.174699          -0.138554        -0.166168   \n",
       "7           -0.184524          -0.174699          -0.144578        -0.167665   \n",
       "1           -0.184524          -0.180723          -0.144578        -0.170659   \n",
       "6           -0.184524          -0.180723          -0.150602        -0.172156   \n",
       "3           -0.196429          -0.198795          -0.138554        -0.178144   \n",
       "9           -0.190476          -0.186747          -0.150602        -0.179641   \n",
       "17          -0.190476          -0.186747          -0.156627        -0.181138   \n",
       "23          -0.190476          -0.180723          -0.186747        -0.184132   \n",
       "2           -0.196429          -0.192771          -0.186747        -0.188623   \n",
       "22          -0.190476          -0.198795          -0.186747        -0.188623   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "14        0.017099                1              -0.164              -0.158   \n",
       "7         0.014713                2              -0.164              -0.158   \n",
       "1         0.015605                3              -0.162              -0.158   \n",
       "6         0.013123                4              -0.162              -0.158   \n",
       "3         0.024075                5              -0.168              -0.168   \n",
       "9         0.016767                6              -0.180              -0.166   \n",
       "17        0.014177                7              -0.182              -0.166   \n",
       "23        0.004742                8              -0.168              -0.162   \n",
       "2         0.006774                9              -0.168              -0.166   \n",
       "22        0.007271                9              -0.168              -0.168   \n",
       "\n",
       "    split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "14           -0.157371           -0.173307         -0.163169         0.006399  \n",
       "7            -0.157371           -0.173307         -0.163169         0.006399  \n",
       "1            -0.163347           -0.175299         -0.164661         0.006449  \n",
       "6            -0.163347           -0.173307         -0.164163         0.005633  \n",
       "3            -0.167331           -0.185259         -0.172147         0.007575  \n",
       "9            -0.167331           -0.185259         -0.174647         0.008209  \n",
       "17           -0.167331           -0.185259         -0.175147         0.008573  \n",
       "23           -0.163347           -0.181275         -0.168655         0.007618  \n",
       "2            -0.163347           -0.181275         -0.169655         0.006909  \n",
       "22           -0.177291           -0.203187         -0.179120         0.014404  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_results = pd.DataFrame(random_cv.cv_results_).sort_values('mean_test_score', ascending = False)\n",
    "\n",
    "random_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.1,\n",
       "                   n_estimators=75, random_state=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = random_cv.best_estimator_\n",
    "final_model.fit(X_train, y_train)\n",
    "pred = final_model.predict(X_test)\n",
    "\n",
    "testfin = pd.read_csv(\"/Users/patrickfahy99/Documents/Kaggle_datasets/titanic/test.csv\")\n",
    "\n",
    "pred = pd.DataFrame(pred, index=testfin[\"PassengerId\"])\n",
    "\n",
    "pred.columns = ['Survived']\n",
    "\n",
    "#final_pred = np.column_stack((testfin[\"PassengerId\"].values, pred.values))\n",
    "\n",
    "#final_pred\n",
    "\n",
    "pred.to_csv(\"/Users/patrickfahy99/Documents/Kaggle_datasets/titanic/submit.csv\", index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
