{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>area_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>concavity_se</th>\n",
       "      <th>concave points_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n",
       "0           0.2419                 0.07871     1.0950      0.9053   \n",
       "1           0.1812                 0.05667     0.5435      0.7339   \n",
       "2           0.2069                 0.05999     0.7456      0.7869   \n",
       "3           0.2597                 0.09744     0.4956      1.1560   \n",
       "4           0.1809                 0.05883     0.7572      0.7813   \n",
       "..             ...                     ...        ...         ...   \n",
       "564         0.1726                 0.05623     1.1760      1.2560   \n",
       "565         0.1752                 0.05533     0.7655      2.4630   \n",
       "566         0.1590                 0.05648     0.4564      1.0750   \n",
       "567         0.2397                 0.07016     0.7260      1.5950   \n",
       "568         0.1587                 0.05884     0.3857      1.4280   \n",
       "\n",
       "     perimeter_se  area_se  smoothness_se  compactness_se  concavity_se  \\\n",
       "0           8.589   153.40       0.006399         0.04904       0.05373   \n",
       "1           3.398    74.08       0.005225         0.01308       0.01860   \n",
       "2           4.585    94.03       0.006150         0.04006       0.03832   \n",
       "3           3.445    27.23       0.009110         0.07458       0.05661   \n",
       "4           5.438    94.44       0.011490         0.02461       0.05688   \n",
       "..            ...      ...            ...             ...           ...   \n",
       "564         7.673   158.70       0.010300         0.02891       0.05198   \n",
       "565         5.203    99.04       0.005769         0.02423       0.03950   \n",
       "566         3.425    48.55       0.005903         0.03731       0.04730   \n",
       "567         5.772    86.22       0.006522         0.06158       0.07117   \n",
       "568         2.548    19.15       0.007189         0.00466       0.00000   \n",
       "\n",
       "     concave points_se  symmetry_se  fractal_dimension_se  radius_worst  \\\n",
       "0              0.01587      0.03003              0.006193        25.380   \n",
       "1              0.01340      0.01389              0.003532        24.990   \n",
       "2              0.02058      0.02250              0.004571        23.570   \n",
       "3              0.01867      0.05963              0.009208        14.910   \n",
       "4              0.01885      0.01756              0.005115        22.540   \n",
       "..                 ...          ...                   ...           ...   \n",
       "564            0.02454      0.01114              0.004239        25.450   \n",
       "565            0.01678      0.01898              0.002498        23.690   \n",
       "566            0.01557      0.01318              0.003892        18.980   \n",
       "567            0.01664      0.02324              0.006185        25.740   \n",
       "568            0.00000      0.02676              0.002783         9.456   \n",
       "\n",
       "     texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0            17.33           184.60      2019.0           0.16220   \n",
       "1            23.41           158.80      1956.0           0.12380   \n",
       "2            25.53           152.50      1709.0           0.14440   \n",
       "3            26.50            98.87       567.7           0.20980   \n",
       "4            16.67           152.20      1575.0           0.13740   \n",
       "..             ...              ...         ...               ...   \n",
       "564          26.40           166.10      2027.0           0.14100   \n",
       "565          38.25           155.00      1731.0           0.11660   \n",
       "566          34.12           126.70      1124.0           0.11390   \n",
       "567          39.42           184.60      1821.0           0.16500   \n",
       "568          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Dataset\n",
    "file = \"/Users/patrickfahy99/Documents/Kaggle_datasets/cancer_data.csv\"\n",
    "data = pd.read_csv(file)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc59d2c4fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check missing values\n",
    "sns.set_style(\"whitegrid\")\n",
    "missing = data.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Unnamed: 32 column\n",
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode letters\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and target dataframes\n",
    "y = data['diagnosis'].reset_index(drop=True)\n",
    "X = data.loc[:, data.columns != 'diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#Create a list of machine learning algorithms\n",
    "models = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "    gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    svm.NuSVC(probability=True),\n",
    "    svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    \n",
    "    XGBClassifier()\n",
    "    ]\n",
    "\n",
    "# Scale the features - so that non tree based methods will be effectvive\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the scaler object with a range of 0-1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit on the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both the training and testing data\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = scaler.transform(X_train)\n",
    "X = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Creating KFold cross validation sets\n",
    "kf = KFold(n_splits=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.949 (0.023), Model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "Accuracy: 0.945 (0.033), Model: BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "Accuracy: 0.954 (0.033), Model: ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
      "                     criterion='gini', max_depth=None, max_features='auto',\n",
      "                     max_leaf_nodes=None, max_samples=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                     warm_start=False)\n",
      "Accuracy: 0.947 (0.021), Model: GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Accuracy: 0.941 (0.026), Model: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Accuracy: 0.949 (0.028), Model: GaussianProcessClassifier(copy_X_train=True, kernel=None, max_iter_predict=100,\n",
      "                          multi_class='one_vs_rest', n_jobs=None,\n",
      "                          n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
      "                          random_state=None, warm_start=False)\n",
      "Accuracy: 0.960 (0.020), Model: LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
      "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
      "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
      "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
      "                     solver='lbfgs', tol=0.0001, verbose=0)\n",
      "Accuracy: 0.956 (0.027), Model: PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "                            early_stopping=False, fit_intercept=True,\n",
      "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
      "                            n_jobs=None, random_state=None, shuffle=True,\n",
      "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
      "                            warm_start=False)\n",
      "Accuracy: 0.954 (0.021), Model: RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]), class_weight=None, cv=None,\n",
      "                  fit_intercept=True, normalize=False, scoring=None,\n",
      "                  store_cv_values=False)\n",
      "Accuracy: 0.976 (0.022), Model: SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Accuracy: 0.945 (0.037), Model: Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
      "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
      "           validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Accuracy: 0.965 (0.011), Model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Accuracy: 0.967 (0.018), Model: SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "Accuracy: 0.943 (0.023), Model: NuSVC(break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "      decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "      max_iter=-1, nu=0.5, probability=True, random_state=None, shrinking=True,\n",
      "      tol=0.001, verbose=False)\n",
      "Accuracy: 0.963 (0.024), Model: LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "Accuracy: 0.949 (0.011), Model: LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "                           solver='svd', store_covariance=False, tol=0.0001)\n",
      "Accuracy: 0.956 (0.016), Model: QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "                              store_covariance=False, tol=0.0001)\n",
      "Accuracy: 0.958 (0.030), Model: XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "# Iterating through the models and finding the cross validation score for each\n",
    "for model in models:\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "    # report performance\n",
    "    if scores.mean() > 0.935:\n",
    "        print('Accuracy: {:.3f} ({:.3f}), Model: {}'.format(scores.mean(), scores.std(), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956043956043956 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Now we look at models that performed well\n",
    "model1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=140,\n",
    " max_depth=2,\n",
    " min_child_weight=5,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=0.0,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "cross_val_score(model1, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "print(model1.score(X_train,y_train), model1.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9846153846153847 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "model2 = svm.SVC(probability=True)\n",
    "cross_val_score(model2, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "print(model2.score(X_train,y_train), model2.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "model3 = ensemble.RandomForestClassifier()\n",
    "cross_val_score(model3, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "print(model3.score(X_train,y_train), model3.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824175824175824 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "model4 = linear_model.LogisticRegressionCV()\n",
    "cross_val_score(model4, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "print(model4.score(X_train,y_train), model4.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9472527472527472 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "model5 = linear_model.SGDClassifier()\n",
    "cross_val_score(model5, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "print(model5.score(X_train,y_train), model5.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9824561403508771 0.9912087912087912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Join these models together\n",
    "eclf1 = VotingClassifier([('a',model1),('b',model2),('c',model3),('d',model4),('e',model5)],\n",
    "                        voting = 'hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "\n",
    "eclf1.predict(X_test)\n",
    "print(eclf1.score(X_test,y_test),eclf1.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc59d51f750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See how this model performs on the test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,eclf1.predict(X_test))\n",
    "sns.heatmap(cm, annot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
